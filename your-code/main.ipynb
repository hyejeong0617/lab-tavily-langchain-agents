{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41222d77",
   "metadata": {},
   "source": [
    "# LAB: Practice with Tavily + LangChain Agents\n",
    "\n",
    "### Objective\n",
    "Reinforce your understanding of LangChain agents integrated with Tavily for real-time web search by solving two open-ended tasks. You'll:\n",
    "- Load and configure a LangChain agent with Tavily\n",
    "- Build effective prompts\n",
    "- Generate structured, useful outputs from real-time data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadf072",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "import tiktoken\n",
    "from IPython.display import Markdown, display\n",
    "from  dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "load_dotenv()\n",
    "tavily_search = TavilySearchResults()\n",
    "\n",
    "# LLM + Encoding\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Safe Tavily wrapper\n",
    "def safe_search(query: str) -> str:\n",
    "    result = tavily_search.run(query)\n",
    "\n",
    "    # Ensure result is a string — Tavily returns dict with 'snippets' sometimes\n",
    "    if isinstance(result, dict):\n",
    "        result_text = result.get(\"content\", \"\") or str(result)\n",
    "    else:\n",
    "        result_text = str(result)\n",
    "\n",
    "    tokens = encoding.encode(result_text)\n",
    "    trimmed = encoding.decode(tokens[:3500])  # leave room for GPT-4 response\n",
    "    return trimmed\n",
    "\n",
    "\n",
    "# LangChain tool\n",
    "tools = [Tool(name=\"TavilySafeSearch\", func=safe_search, description=\"Web search tool\")]\n",
    "agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089593a",
   "metadata": {},
   "source": [
    "### Exercise 1: AI in Healthcare\n",
    "\n",
    "Goal: Investigate and summarize the latest advancements in generative AI applied to healthcare in 2025.\n",
    "\n",
    "- Design a prompt that asks the agent to retrieve the most recent updates.\n",
    "- Ensure the agent outputs a structured response in Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your prompt here\n",
    "prompt_1 = \"\"\n",
    "\n",
    "# Run it\n",
    "response_1 = agent.run(prompt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab2627",
   "metadata": {},
   "source": [
    "### Exercise 2: AI Startups Landscape\n",
    "\n",
    "Goal: Track 2025’s top emerging AI startups and their innovations.\n",
    "\n",
    "- Create a prompt that instructs the agent to deliver a clean Markdown summary.\n",
    "- Tip: Ask for company names, product highlights, and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your prompt here\n",
    "prompt_2 = \"\"\n",
    "\n",
    "# Run it\n",
    "response_2 = agent.run(prompt_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b8fda",
   "metadata": {},
   "source": [
    "### Exercice 3: Compare Two Tech Products\n",
    "- **Prompt idea:** Compare the key features, pricing, and reviews of OpenAI’s ChatGPT Team and Anthropic’s Claude Pro.\n",
    "- Ensure the agent outputs a structured response in Markdown.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your prompt here\n",
    "prompt_3 = \"\"\n",
    "\n",
    "# Run it\n",
    "response_3 = agent.run(prompt_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response_3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f40dbe3",
   "metadata": {},
   "source": [
    "## Bonus Task: Propose and Implement Your Own Use Case\n",
    "\n",
    "As a final challenge, think of a real-world scenario where an AI agent could provide value using web search or external tools.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
